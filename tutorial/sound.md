Немножко про теорию звука
=========================
Я попробую на пальцах описать некоторые основные понятия, которые требуется знать, при цифровой обработке звука. 
В этом разделе нет серьёзной математики вроде быстрых преобразований Фурье и прочего - эти формулы не сложно найти в 
сети. Тут описывается только сама суть и смысл вещей с которыми придётся столкнуться.

Оцифровка, или Туда и обратно
-----------------------------
Прежде всего разберёмся с тем, что такое цифровой сигнал, как он получается из аналогового и откуда собственно берётся
аналоговый сигнал. Максимально просто аналоговый сигнал можно описать как колебания напряжения возникающие из-за
колебаний мембраны в микрофоне. Как выглядит этот сигнал можно посмотреть введя в поиске запрос
[осциллограмма звука](https://yandex.ru/images/search?text=осцилллограмма%20звука), думаю каждый хоть раз в жизни видел
подобные картинки. Как же происходит преобразование аналогового сигнала в цифровой? Для того чтобы понять этот процесс
нужно нарисовать осциллограмму звука на миллеметровой бумаге. Теперь для каждой вертикальной линии найти точку
пересечения с осциллограммой и найти ближайшее целое значение по вертикальной шкале. Собственно набор таких значений
и будет простейшей записью цифрового сигнала.

Чтобы лучше разобраться с тем, как накладываются друг на друга волны разной частоты и как происходит оцифровка можно
воспользоваться [данным интерактивным примером](https://www.desmos.com/calculator/xbkiqg5mik). В левом меню можно
включать/выключать отображение графиков, настраивать параметры входных данных и параметры дискретизации.

На [аппаратном уровне](https://ru.wikipedia.org/wiki/Аналого-цифровой_преобразователь) это разумеется выглядит значительно
сложнее и сигнал может кодироваться совершенно разными способами в зависимости от аппаратуры. Самым распространённым
способом кодирования является [импульсно-кодовая модуляция](https://ru.wikipedia.org/wiki/Импульсно-кодовая_модуляция)
при которой записывается не конкретное значение уровня сигнала в каждый момент времени, а разница между текущим и
предыдущим значением - это позволяет снизить количество бит на каждый отсчёт примерно на 25%. Этот способ кодирования
используется в наиболее распространённых аудио-форматах (MP3, WAV, WMA, OGG, FLAC, APE).

В реальности при записи аудио чаще всего записывается не один, а сразу несколько каналов, для создания стерео-эффекта. В
зависимости от используемого формата хранения эти каналы могут храниться независимо или же уровни сигнала могут 
записываться как разница между уровнем основного канала и уровнем текущего.

Обратное преобразование из цифрового сигнала в аналоговый производится с помощью 
[цифро-аналоговых преобразователей](https://ru.wikipedia.org/wiki/Цифро-аналоговый_преобразователь), которые могут иметь
различное устройство и принципы работы. Я опущу описание этих приницпов в данной статье, т.к. это сугубо технические
детали, которые имеют малое отношение к цифровой обработке сигналов.

Дискретизация
-------------
Как уже было сказано, цифровой сигнал это набор значений уровня сигнала записанный через заданные промежутки времени.
Процесс преобразования неприрывного аналогового сигнала в дискретный цифровой сигнал называется дискретизацией.
Есть 2 основных характеристики цифрового сигнала - частота дискретизации и глубина дискретизации по уровню. 

[Частота дискретизации](https://ru.wikipedia.org/wiki/Частота_дискретизации) указывает с какими интервалами по времени
идут данные об уровне сигнала. Существует [теорема Котельникова](https://ru.wikipedia.org/wiki/Теорема_Котельникова)
(в западной литературе её упомянают как теорему Найквиста - Шеннона, хотя встречается и название Котельникова - Шеннона),
которая утверждает, что для возможности точного восстановления аналогового сигнала из дискретного требуется, чтобы 
частота дискретизации была минимум в 2 раза выше, чем максимальная частота в аналоговом сигнале. Если брать примерный
диапазон воспринимаемых человеком частот звука 20Гц - 20КГц, то оптимальная частота дискретизации 
([частота Найквиста](https://ru.wikipedia.org/wiki/Частота_Найквиста)) должна быть в районе 40КГц. У стандартных 
аудио-CD частота дискретизации составляет 44.1КГц 

[Глубина дискретизации](https://ru.wikipedia.org/wiki/Квантование_(обработка_сигналов%29) по уровню - описывает
разрядность числа, которым описывается уровень сигнала. Эта характеристика накладывает ограничение на точность записи
уровня сигнала и на его минимальное значение. Стоит спеицально отметить, что данная характеристика не имеет отношения
к громкости - это характеристика отражающая точность записи сигнала. Стандартная глубина дискретизации на audio-CD 
16 бит. При этом разница в звучании перестаёт быть заметна большинством уже в районе 10-12 бит, если не 
использовать специальную студийную аппаратуру. Однако большая глубина дискретизации позволяет избежать появления 
шумов при дальнейшей обработке звука.

Шумы
----
В цифровом звуке можно выделить 3 основных источника шумов

### Джиттер
[Джиттер](https://ru.wikipedia.org/wiki/Джиттер) - это случайные отклонения сигнала, как правило возникающие из-за 
нестабильности частоты задающего генератора или различной скорости распространения разных частотных составляющих 
одного сигнала. Данная проблема возникает на стадии оцифровки.

### Шум дробления
Шум дробления напрямую связан с глубиной дискретизации. Т.к. при оцифровке сигнала реальные значения сигнала округляются
с определённой точностью возникают слабые шумы, связанные с потерей точности. Эти шумы могут возникать не только на
стадии оцифровки, но и в процессе цифровой обработки, например если сначала уровень сигнала сильно понижается, а затем
снова повышается.

### Алиасинг
При оцифровке возможна ситуация, при которой в цифровом сигнале могут появиться частотные составляющие отсутствующие в
оригинальном сигнале. Данная ошибка получила название [alias](https://ru.wikipedia.org/wiki/Алиасинг). Этот эффект
напрямую связан с частотой дискретизации, а точнее с [частотой Найквиста](https://ru.wikipedia.org/wiki/Частота_Найквиста).
Проще всего понять это рассмотрев данное изображение:
[<img src='https://upload.wikimedia.org/wikipedia/commons/2/28/AliasingSines.svg?uselang=ru' width='100%' />](https://ru.wikipedia.org/wiki/Алиасинг)
Красным показана частотная составляющая, частота которой выше частоты Найксвита. При оцифровке такой частотной
составляющей не удаётся записать достаточно данных для её корректного описания. В результате при воспроизведении 
получается совершенно другой сигнал - синяя кривая.


Уровень сигнала
---------------
Для начала стоит сразу понять, что когда речь идёт о цифровом сигнале можно говорить только об относительном уровне
сигнала. Абсолютный уровень сигнала зависит в первую очередь от воспроизводящей аппаратуры и он прямо пропорционален 
относительному уровню цифровго сигнала. При расчётах относительных уровней сигнала принято использовать 
[децибелы](https://ru.wikipedia.org/wiki/Децибел). При этом за точку отсчёта берётся сигнал с максимально возможной 
амплитудой при заданной глубине дискретизации. Этот уровень указывается как 0 dBFS (dB - децибел, 
FS = Full Scale - полная шкала). Более низкие уровни сигнала указываются как -1 dBFS, -2 dBFS и т.д. Вполне очевидно, 
что более высоких уровней просто не бывает (мы изначально берём максимально возможный уровень).

По началу бывает тяжело разобраться с тем, как соотносятся децибелы и реальный уровень сигнала. Тут на самом деле всё
просто. Каждые ~6 dB (Точнее 20 * log(2) ~ 6.02 dB) указывают на изменение уровня сигнала в 2 раза. То есть если мы 
говорим, о сигнале с уровнем -12 dBFS - это сигнал уровень которого в 4 раза меньше, чем максимальный. *Написать чуток
математики для объяснения почему это так*

При различной глубине дискретизации уровень сигнала по этой шкале изменяться не будет. Сигнал с уровнем -6 dBFS 
останется сигналом с уровнем -6 dBFS. Но всё же одна характеристика изменится - динамический диапазон. Динамический 
диапазон сигнала - это разница между его минимальным и максимальным значением. Он рассчитывается по формуле 
`n * 20 log(2)`, где n - глубина дискретизации (для грубых оценок можно пользоваться более простой формулой: `n * 6`). 
Для 16 бит это ~96.33 dB, для 24 бит ~144.49 dB. Это означает, что самый большой перепад уровня, который можно описать 
с 24-битной глубиной дискретизации (144.49 dB) на 48.16 dB больше, чем самый большой перепад уровня с 16-битной глубиной 
(96.33 dB). Плюс к тому шум дробления при 24 битах на 48 dB тише.

Восприятие
----------
Когда речь идёт о восприятия звука человеком, следует сначала разобраться о том, каким образом мы воспринимаем звук.
Очевидно, что мы слышим с помощью [ушей](https://ru.wikipedia.org/wiki/Ухо). Звуковые волны взаимодействуют с барабанной
перепонкой, смещая её, вибрации передаются во внутренее ухо, где их улавливают рецепторы. То на сколько смещается
барабанная перепонка зависит от такой характеристики как 
[звуковое давление](https://ru.wikipedia.org/wiki/Звуковое_давление). При этом 
[воспринимаемая громкость](https://ru.wikipedia.org/wiki/Громкость_звука) зависит от звукового давления не напрямую, 
а логарифмически. Поэтому при изменении громкости принято использовать относительную шкалу SPL (уровень звукового 
давления), значения которой указываются всё в тех же децибелах. Стоит также заметить, что воспринимаемая громкость звука 
зависит не только от уровня звукового давления, но ещё и от частоты звука:
  
[<img src='https://upload.wikimedia.org/wikipedia/commons/3/37/Gromkost.png?uselang=ru' width="100%" />](https://ru.wikipedia.org/wiki/Громкость_звука)

Громкость
---------
Простейшим примером обработки звука является изменение его громкости. При этом происходит просто умножение уровня
сигнала на некоторое фиксированное значение. Однако даже в таком простом деле как регулировка громкости есть один
подводный камень. Как я уже отметил ранее, воспринимаемая громкость зависит от логарифма звукового давления, а
это значит, что использование линейной шкалы громкости не оказывается не очень эфективным. При линейной шкале громкости
возникает сразу 2 проблемы - для ощутимого изменения громкости, когда ползунок находится выше середины шкалы приходится 
достаточно далеко его сдвигать, при этом ближе к самому низу шкалы сдвиг меньше чем на толщину волоса может изменить
громкость в 2 раза (думаю с этим каждый сталкивался). Для решения данной проблемы используется логарифмическая шкала
громкости. При этом на всей её длинне передвижение ползунка на фиксированное расстояние меняет громкость в одинаковое
количество раз. В профессиональной записывающей и обрабатывающей аппаратуре как правило используется именно
логарифмическая шкала громкости. 

### Математика
Тут я пожалуй немного вернусь к математике, т.к. реализация логарифмическое шкалы оказывается не такой простой и 
очевидной вещью для многих, а найти в интернете данную формулу не так просто, как хотелось бы. Заодно покажу как просто
переводить значения громкости в dBFS и обратно. Для дальнейших объяснений это будет полезным.

```javascript
// Минимальное значение громкости - на этом уровне идёт отключение звука
var EPSILON = 0.001;

// Коэфициент для преобразований в dBFS и обратно
var DBFS_COEF = 20 / Math.log(10);

// По положению на шкале вычисляет громкость
var volumeToExponent = function(value) {
    var volume = Math.pow(EPSILON, 1 - value);
    return volume > EPSILON ? volume : 0;
};

// По значению громкости вычисляет положение на шкале
var volumeFromExponent = function(volume) {
    return 1 - Math.log(Math.max(volume, EPSILON)) / Math.log(EPSILON);
};

// Перевод значения громкости в dBFS
var volumeToDBFS = function(volume) {
    return Math.log(volume) * DBFS_COEF;
};

// Перевод значения dBFS в громкость
var volumeFromDBFS = function(dbfs) {
    return Math.exp(dbfs / DBFS_COEF);
}
```

### Цифровая обработка
Теперь вернёмся к тому, что мы имеем цифровой, а не аналоговый сигнал. У цифрового сигнала есть 2 особенности, которые
стоит учитывать при работе с громкостью:
  
  - точность, с которой указывается уровень сигнала ограничена (причём достаточно сильно. 16 бит - это в 2 раза меньше,
   чем используется для стандартного числа с плавающей точкой)
  - у сигнала есть верхняя граница уровня. За эту границу уровень сигнала выйти не может.

Из итого что уровень сигнала имеет ограничение точности следует две вещи:

  - уровень шумов дробления возрастает при увеличиении громкости. Обычно это не критично, т.к. изначальный уровень шума
  значительно тише ощутимого и его можно безопасно поднимать в 4-8 раз.
  - не стоит сначала сильно понижать уровень сигнала, а затем сильно его повышать - при этом могут появиться новые
  шумы дробления, которых изначально не было.

Из того, что сигнал имеет верхнее ограничение уровня следует, что нельзя безопасно увеличивать громкость выше 
единицы. При этом пики, которые окажутся выше границы будут "срезаны" и произойдёт потеря данных.

### Измерение громкости
Для того, чтобы сравнивать громкость двух разных сигналов, для начала её нужно как-то измерить. Существует по меньшей
мере 3 метрики для измерения громкости сигналов - максимальное пиковое значение, усреднённое значение уровня сигнала и
метрика ReplayGain.

Максимальное пиковое значение достаточно слабая метрика для оценки громкости - она никак не учитывает общий уровень
громкости - например если записать грозу, то большую часть времени на записи будет тихо шелестеть дождь и лишь пару 
раз прогремит гром. Максимальное пиковое значение уровня сигнала у такой записи будет довольно высоким, но большая 
часть записи будет иметь весьма низкий уровень сигнала. Однако эта метрика всё равно является полезной - она позволяет
вычислить максимальное усиление, которое можно применить к записи, при котором не будет потерь данных из-за "обрезания"
пиков.

Усреднённое значение уровня сигнала метрика более полезная и легко вычислимая, но всё же имеет существенные недостатки
связанные с тем, как мы воспринимаем звук. Визг цикрулярной пилы и рокот водопада, записанные с одинаковым средним
уровнем сигнала, будут восприниматься совершенно по разному.

[ReplayGain](https://en.wikipedia.org/wiki/ReplayGain) - метрика наиболее точно передающая воспринимаемый уровень
громкости записи, которая учитывает физиологические и психические особенности восприятия звука. Для промышленного 
выпуска записей многие звукозаписывающие студии используют именно её, также она поддерживается большинством популярных
медиа-плееров.
*(PS. [русская статья](https://ru.wikipedia.org/wiki/Replay_Gain) на WIKI содержит много неточностей и фактически не
корректно описывает саму суть технологии)*

### Нормализация громкости
Если мы можем измерять громкость различных записей, мы можем её нормализовать. Идея нормализации громкости состоит в 
том, чтобы привести разные звуки к одинаковому уровню воспринимаемой громкости. Для этого используется несколько 
различных подходов. Как правильно громкость стараются максимизировать, но это не всегда возможно из-за ограничений 
максимального уровня сигнала, поэтому обычно берётся некоторое значение немного меньше максимума типа -14 dBFS, к
которому пытаются привести все сигналы.

Иногда нормализацию громкости производят в рамках одной записи - при этом различные части записи усиливают на разные
величины, чтобы их воспринимаемаемая громкость была одинаковой. Такой подход очень часто применяется в компьютерных
видео-плеерах - звуковая дорожка многих фильмов может содержать участки с очень сильно отличающейся громкостью. При
этом возникают проблемы при просмотре фильмов без наушников в позднее время - при громкости на которой нормально слышен
шёпот главных героев, выстрелы способны перебудить соседей. А на громкости при котороый выстрели не бьют по ушам шёпот
становится вообще неразличим. При внутритрековой нормализации громкости плеер автоматически увеличивает громкость на
тихих участках и понижает на громких. Однако этот подход создаёт ощутимые артефакты воспроизведения при резких переходах
между тихим и громким звуком, а также порой завышает громкость некоторых звуков, которые по задумке должны быть фоновыми
и еле-различимыми.

Также внутреннюю нормализацию порой производят с целью повышения общей громкости треков. Это называется нормализацией с 
компрессией. При этом подходе среднее значение уровня сигнала максимизируется за счёт усиления всего сигнала на заданную
величину. При этом те участки, которые должны были быть подвергнуты "обрезанию" из-за превышения максимального уровня
усиливаются на меньшую величину, позволяя избежать этого. Этот способ увеличения громкости значительно снижает качество
звучания трека, но тем не менее многие звуко-записывающие студии не брезгают его применять.

Фильтрация
----------
Я не стану описывать совсем все аудио-фильтры, ограничусь только стандартными, которые присутсвуют в Web Audio API.

### Глушащие фильтры
Самый простой в понимании вид фильтров - они просто заглушают определённые частоты. В зависимости от типа фильтра,
применяются разные правила для выбора частот, которые заглушаются.

#### lowpass - фильтр нижних частот
Фильтр, который пропускает частоты ниже заданной частоты. При этом на граничных частотах не происходит резкого 
перепада - фильтр имеет затухание 12 dB на октаву. *Требуется уточнение на тему параметра Q*

#### highpass - фильтр высоких частот
Фильтр действует аналогично lowpass, за исключением того, что он пропускает частоты выше заданной, а не ниже.

#### bandpass
Данный фильтр более изберателен - он пропускает только определённую полосу частот. Фильтр задаётся центральной частотой,
полосы пропускания и коэфициентом Q, отвечающим за ширину полосы пропускания. *Требуется уточнение какие значения как
влияют. Есть предположение, что Q = 1 -> 12dB на октаву, Q = 2 -> 24dB на октаву и т.д.*

#### notch
Фильтр является противоположностью bandpass - он пропускает все частоты, вне заданной полосы.

### Усиливающие фильтры
Данные фильтры могут усиливать или ослабрять определённые наборы частот в зависимости от типа и настроек.

#### lowshelf
Является более "умной" версией highpass - он усиливает или ослабляет частоты ниже заданной, частоты выше пропускает без
изменений.

#### highshelf
Является более "умной" версией lowpass - он усиливает или ослабляет частоты выше заданной, частоты ниже пропускает без
изменений.

#### peaking
Является более "умной" версией notch - он усиливает или ослабляет частоты в заднном диапазоне и пропускает остальные
частоты без изменений.

### Фильтр allpass
Этот фильтр отличается от всех остальных - они меняют только амплитудные характеристики сигнала. Данный фильтр оставляет
амплитудные характеристики неизменными, вместо этого он делает фазовый сдвиг заданных частот. Фильтр задаётся центральной
частотой и силой фазового сдвига. *Требуется уточнение правильно ли я уловил суть. Требуется уточнение как именно
параметр Q влияет на фазовый сдвиг и как выглядит функция затухания эффекта данного фильтра*

### Фильтр WaveShaperNode
Этот фильтр реализует эффект distortion. *Требуется нормальное описание. Даже Mozilla не знает толком что это такое и
как с этим работать* [Статья на developer.mozilla.org](https://developer.mozilla.org/en-US/docs/Web/API/WaveShaperNode)

### Фильтр ConvolverNode
Фильтр производящий линейную свёртку с заданным аудио-буффером. *Требуется нормальное описание. Моих знаний математики
явно не достаточно для описания что такое свёрстка двух функций человеческим языком. И я не совсем уверен, что это
вообще можно описать человеческим языком*
