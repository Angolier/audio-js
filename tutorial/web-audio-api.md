Web Audio API
=============

Web Audio API - это технология, позволяющая существенно расширить возможности воспроизведения звука в браузере. К сожалению эта технология на данный момент очень молодая и её поддержка есть только в свежих версиях популярных десктопных браузеров и практически отсутствует в мобильных браузерах.
  
У Web Audio API стоит выделить 3 основных аспекта, которые особо не пересекаются и их можно рассматривать отдельно:
 
  - возможности работы с различными источниками сигнала
  - возможности по анализу сигнала
  - возможности по цифровой обработке сигнала
  
Источники сигнала
-----------------

Web Audio API работает с цифровыми сигналами, которые могут быть получены из самых разных источников или созданы непосредственно с помощью скриптов. Элементы Web Audio API, которые могут генерировать некий сигнал будем называть источниками сигнала, а любые посторониие объекты, которые могут быть использованы для генерации этого сигнала будем называть источниками данных.

В отличие от медиа-элементов у Web Audio API нет методов получения данных по сети или из файловой системы. Вместо этого есть 3 типа источников данных, которые позволяют решать проблему получения данных самыми разнообразными способами, которые не доступны медиа-элементам.

### [MediaElementAudioSourceNode](https://developer.mozilla.org/en-US/docs/Web/API/MediaElementAudioSourceNode)

Начнём с самого простого. Источником данных этого элемента является ```<audio>``` или ```<video>``` элемент. 

Фабрика ```AudioContext#createMediaElementSource``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createMediaElementSource)) принимает в качестве единственного параметра медиа-элемент (```<audio>``` или ```<video>```). При этом создание ```MediaElementAudioSourceNode``` перенапрявляет вывод аудио-потока из медиа-элемента в данный объект. Остальное поведение медиа-элемента при этом не изменяется. 

Стоит отметить 2 вещи:
  
   - у медиа-элемента по прежнему работают функции изменения громкости. Для целей воспроизведения это может не иметь особого значения, но если требуется проводить анализ сигнала лучше всего выставить медиа-элементу максимальную громкость, а итоговую громкость на выходе регулировать с помощью GainNode (об этом ещё будет рассказано позднее)
   - Web Audio API требует специальных прав на получение данных из медиа-элемента. Если трек загружается с другого сервера, то для корректной работы ```MediaElementAudioSourceNode``` требуется, чтобы у медиа-элемента был выставлен параметр ```crossOrigin``` и в ответах сервера приходил корректный заголовок ```Access-Control-Allow-Access```. В противном случае этот элемент нельзя будет использовать в качестве источника данных для Web Audio API.

### [MediaStreamAudioSourceNode](https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamAudioSourceNode)

Источником данных этого элемента является аудио-вход или любой другой источник настроенный в системе или браузере пользователя. 

Фабрика ```AudioContext#createMediaStreamSource``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createMediaStreamSource)) принимает в качестве единственного параметра медиа-поток, получаемый из метода ```MediaDevices.getUserMedia``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia)). Основное применение данного источника - использование микрофона или линейного входа в качестве источника аудио-данных. Тут вроде подводных камней нет.

### [AudioBufferSourceNode](https://developer.mozilla.org/en-US/docs/Web/API/AudioBufferSourceNode)

Источником данных этого элемента является [AudioBuffer](https://developer.mozilla.org/en-US/docs/Web/API/AudioBuffer). Это пожалуй самый интересный тип источников сигнала, т.к. он предоставляет те возможности, которые отсутсвуют у медиа-элементов. С помощью аудио-буфера можно формировать любой сигнал непосредственно в браузере (например таким образом это делается здесь [wavepot.com](http://wavepot.com/)). 

Фабрика ```AudioContext#createBufferSource``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createBufferSource)) в отличие от предыдущих источников не принимает элемент буфера в качестве аргумента - он устанавливается вручную после создания элемента (например ```audioBufferSource.buffer = audioBuffer```).

AudioBuffer может быть сформирован множеством разных способов. 

#### Непосредственное создание и заполнение буфера

Самый банальный метод - непосредственное создание и заполнение этого буфера. Конструктор ```AudioContext#createBuffer``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createBuffer)) принимает 3 параметра:

  - количество каналов
  - количество семплов
  - частоту дискретизации

Буфер может иметь до 32 каналов. Каждый канал содержит информацию о сигнале в формате PCM.

#### Декодирование сжатых аудио-данных

Также можно создать буфер из сжатых аудио-данных. Для этого используется метод ```AudioContext#decodeAudioData``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/decodeAudioData)). Он принимает 2 параметра:

  - сжатые аудио-данные
  - обработчик в который будет передан объект ```AudioBuffer``` с декодированными данными
  
Благодаря этому методу можно не только вручную контролировать процесс загрузки данных, но и допустим сохранять их в localStorage (для больших файлов не подойдёт, но короткий "блямк" вполне можно сохранить). Однако стоит помнить про то, что буфер содержит несжатые данные. Каждый семпл в каждом канале - это 32 битное число с плавающей точкой, так что 5 минутный стерео-трек займёт 106 мегабайт памяти. Так что если вы решите загрузить целиком 9 симфонию Бетховена (длительность аудио-диска 74 минуты - длительность этой симфонии), то она займёт 783 мегабайта в моно-режиме и 1,5 гигабайта в стерео.

#### Использование [OfflineAudioContext](https://developer.mozilla.org/en-US/docs/Web/API/OfflineAudioContext)

Самый нетривиальный метод создания аудио-буффера. Элемент ```OfflineAudioContext``` работает примерно также как обычный ```AudioContext```, но вместо вывода аудио-потока на устройства воспроизведения, он рассчитывает аудио-буфер. Конструктор принимает те же параметры что и ```AudioContext#createBuffer```. 

Фактически данный элемент позволяет произвести необходимые преобразования звука заранее, а затем многократно переиспользовать полученный аудио-буфер вместо повторных вычислений в рантайме. Возможности по формированию и обработке сигнала в данном случае ограничены только воображением.

### [OscillatorNode](https://developer.mozilla.org/en-US/docs/Web/API/OscillatorNode)

Этот элемент - самый простой и логичный генератор сигналов. Он просто генерирует периодический сигнал с заданной частотой. Форму волны при этом можно задавать указывая один из заранее заданных [типов](https://developer.mozilla.org/en-US/docs/Web/API/OscillatorNode/type) или с помощью элементов ```PeriodicWave``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/PeriodicWave)).

Фабрика ```AudioContext#createOscillator``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createOscillator)) не принимает аргументов. Вся настройка происходит уже после создания. (Например ```oscillator.frequency.value = 3000```).

```PeriodicWave``` - является элементом, описывающим форму некоторой периодически повторяющейся волны. Форма волны задаётся с помощью коэффициентов для обратного Быстрого Преобразование Фурье. Максимальное колличество коэфициентов = 4096

Фабрика ```AudioContext#createPeriodicWave``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createPeriodicWave)) принимает 3 аргумента:

  - массив коэффициентов для обратного Быстрого Преобразования Фурье (действительная часть)
  - массив коэффициентов для обратного Быстрого Преобразования Фурье (мнимая часть)
  - опциональный объект ```{disableNormalization: true}```, отключающий нормализацию волны

Чтобы понять как разные коэфициенты влияют на форму волны можно посмотреть данную [демонстрацию](https://www.desmos.com/calculator/lmzpimpbou). Под графиком расположены 8 контрольных точек, которые можно передвигать чтобы изменять коэффициенты. По оси x отсчитывается действительная часть коэффициента, по оси y - мнимая. Графики отображают действительную и мнимую часть волны после обратного Преобразования Фурье.

Стоит учитывать однако, что вне зависимости от количеста коэффициентов, которые будут переданы в фабрику общее количество отсчётов, которое будет использовано для обратного преобразования будет равно 4096. **ТРЕБУЕТСЯ ПЕРЕПРОВЕРИТЬ ПРАВИЛЬНО ЛИ Я РАЗОБРАЛСЯ В КОДЕ**

Анализ сигнала
--------------

Для анализа данных аудио-потока можно использовать 2 различных подхода:

  - анализ данных непосредственно из аудио-буффера (Web Audio API в этом нам не помощник, оно только предоставит массив данных - дальше нужно самостоятельно описывать функции обработки этих данных)
  - анализ данных с помощью ```AnalyserNode``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode))
  
### AudioBuffer

Я не буду здесь расписывать каким образом можно использовать данные аудио-буфера, т.к. это не относится к Web Audio API напрямую. Получить данные любого канала можно с помощью методов ```AudioBuffer#getChannelData``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/AudioBuffer/getChannelData)) и ```AudioBuffer#copyFromChannel``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/AudioBuffer/copyFromChannel))

### [AnalyzerNode](https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode)

Данный элемент используется для анализа данных аудио-потока в реальном времени. 

Фабрика ```AudioContext#createAnalyser``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createAnalyser)) не принимает никаких аргументов. Все настройки осуществляются после создания элемента. (Например ```analyser.fftSize = 2048;```)

Фактически данный элемент содержит в себе буффер данных, который заполняется по мере воспроизведения потока. К этому буферу применяется Быстрое Преобразование Фурье. Данные преобразования можно получить с помощью методов ```AnalyserNode#getFloatFrequencyData``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode/getFloatFrequencyData), передаёт данные в Float32Array) и ```AnalyserNode#getByteFrequencyData``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode/getByteFrequencyData), передаёт данные в Uint8Array). Данные анализируемого буфера можно получить с помощью методов ```AnalyserNode#getFloatTimeDomainData``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode/getFloatTimeDomainData), передаёт данные в Float32Array) и ```AnalyserNode#getByteTimeDomainData``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode/getByteTimeDomainData), передаёт данные в Uint8Array).

#### Быстрое Преобразование Фурье

В статье про [теорию звука](https://github.yandex-team.ru/pages/music/audio/tutorial-sound.html) я постарался избежать описания данного алгоритма, но здесь стоит о нём рассказать, чтобы было понятно для чего он нужен и какие данные с помощью него можно получить.

Быстрое Преобразование Фурье (БПФ), грубо говоря, это ускоренная версия Дискретного Преобразования Фурье (ДПФ), которое позволяет для дискретного сигнала (а цифровой сигнал как раз таким и является) получить набор частотных и фазовых характеристик этого сигнала в виде набора комплексных чисел. Вообще говоря это преобразование над комплексными числами, но в цифровом сигнале у нас есть только вещественная часть, и все мнимые компоненты у нас будут равны нулю. Отличие алгоритмов БПФ И ДПФ пожалуй лишь с в скорости работы и том, что БПФ требует чтобы количество входных данных было равно 2^n. **ПРОВЕРИТЬ ЧТО ЭТО ТАК ДЛЯ БПФ И НЕ ТАК ДЛЯ ДПФ**

Чтобы понять для чего нужно ДПФ проще всего рассмотреть обратное ДПФ. Входными данными для этого преобразования является набор комплексных чисел, которые отражают частотные и фазовые характеристики некого сигнала, а выходными данными является непосредственно сам цифровой сигнал. Каков смысл этих чисел? На самом деле всё просто. Рассмотрим [демонстрацию](https://www.desmos.com/calculator/lmzpimpbou), которую я уже приводил в разделе про ```PeriodicWave```. В этой демонстрации строится непрерывная бесконечная функция, а не дискретный конечный сигнал, но в плане наглядности так даже лучше. Нас будет интересовать только часть ограниченная 2 вертиальными оранжевыми линиями.

Вещественная часть самого первого аргумента всего лишь поднимает/опускает вещественную часть в результирующей функции. Мнимая часть делает тоже самое с мнимой частью функции.
 
Остальные аргументы более интересны. Модуль любого из этих чисел указывает амплитуду некой синусоиды, а аргумент числа - фазу этой синусоиды в точке 0. Длина волны каждой синусоиды зависит от порядкового номера числа L = N / (n - 1), где L - длина волны в системе координат преобразования, N - количество отсчётов, n - порядковый номер аргумента. Таким образом второй аргумент задаёт синусоиду с длинной волны равной количеству отсчётов, третий - с длинной волны в 2 раза меньше, четвёртый - с длинной волны в 3 раза меньше и т.д. Все полученные синусоиды просто складываются друг с другом по принципу суперпозиции.

Собственно если обратное ДПФ из коэффициентов строит цифровой сигнал, то прямое ДПФ из цифрового сигнала получает эти самые коэффициенты, т.е. позволяет разложить наш сигнал в набор косинусоид различной частоты.

#### Интерпретация данных AnalyzerNode

```AnalyzerNode``` возвращает 2 набора данных - частотные характеристики и форму волны. Тут есть несколько подводных камней и особенностей. 

Почему-то нигде в документации не описано в каком формате методы ```AnalyserNode#getFloatFrequencyData``` и ```AnalyserNode#getByteFrequencyData``` возвращают данные, сказано лишь, что эти данные получаются из БПФ. Нам известно, что БПФ возвращает набор комплексных чисел. Первой мыслью было, что данные методы возвращают просто модули этих чисел, но это оказалось не так. Возвращаемые данные условно разделены на 2 равных части. Первая половина данных содержит модули (т.е. значения амплитуды), а вторая часть - аргументы (т.е. значения фазовых сдвигов). И это ещё не всё. Для метода ```AnalyserNode#getFloatFrequencyData``` данные об амплитуде указываются по шкале dBFS, а для метода ```AnalyserNode#getByteFrequencyData``` эта шкала ещё и перенормируется с учётом параметров ```AnalyserNode#minDecibels``` и ```AnalyserNode.maxDecibels```. Не очевидно ещё вот что: размер данных о частотных характеристиках в 2 раза меньше, чем размер буфера (```AnalyserNode.fftSize```), а БПФ должно выдавать данные соответствующие размеру буфера. Половина данных из этих результатов просто выбрасывается. Чуть позже объясню почему для анализа она действительно мало интересна.

Выше была рассмотрена интерпретация значений частотных характеристик в системе координат преобразования, теперь стоит рассмотреть интерпретацию в системе координат цифрового сигнала. Чему равна реальная частота каждого из аргументов? Это зависит от 2х параметров: частоты дискретизации самого цифрового сигнала и размера буфера преобразования. Зависимость частоты от номера аргумента получается такая: D * (n - 1) / B, где D - частота дискретизации сигнала, B - размер буфера, n - номер аргумента. Из этого следует интересное свойство - середина буфера соответствует частоте Найквиста. Именно поэтому половина буфера выбрасывается из выдачи - она описывает частоты выше частоты Найквиста. Частоту дискретизации сигнала можно узнать из ```AudioContext#sampleRate```.

С методами ```AnalyserNode#getFloatTimeDomainData``` и ```AnalyserNode#getByteTimeDomainData``` всё несколько проще - оба метода просто возвращают значения временного буфера. Значения первого идут в диапазоне от -1 до 1, значения второго - от 0 до 255.

Обработка сигнала
----------------

Основное назначние Web Audio API - это обработка сигналов. Для этих целей есть целый арсенал различных фильтров.

### [GainNode](https://developer.mozilla.org/en-US/docs/Web/API/GainNode)

Самый простой фильтр - он просто меняет громкость сигнала. При изменении значения усиления используется специальный алгоритм, который предотвращает возникновение щелчков. В отличие от большинства других фильтров, здесь используется линейная шкала усиления, а не логарифмическая (в децибелах).

Фабрика ```AudioContext#createGain``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createGain)) не принимает никаких параметров. Все настройки делаются после создания элемента (например ```gainNode.gain.value = 0.6```)

### [DelayNode](https://developer.mozilla.org/en-US/docs/Web/API/DelayNode)

Фильтр реализующий линию задержки. Фактически он создаёт задержку выходного сигнала относительно входного. Обычно используется для синхронизации различных сигналов во времени. Также данный элемент критически необходим для ситуаций, когда граф обработки сигнала содержит циклы. Если в таком графе не будет ни одного элемента ```DelayNode```, то все ноды входящие в цикл будет отключены.

Фабрика ```AudioContext#createDelay``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createDelay)) принимает в единственного параметра время задержки. Однако не стоит считать, что время задержки является фиксированным для элемента - его можно изменять после создания: ```delayNode.delayTime.value = 4```
 
### [BiquadFilterNode](https://developer.mozilla.org/en-US/docs/Web/API/BiquadFilterNode)

Биквадратный фильтр относится к классу фильтров с бесконечной импульсной характеристикой (БИХ), он использует 2 последних отсчёта из входного сигнала, 2 последних отсчёта из выходного сигнала и текущий уровень сигнала. Эти параметры умножаются на зарнее расчитанные коэффициенты и складываются. С помощью различных коэффициентов реализуется большое количество разнообразных фильтров.

Фабрика ```AudioContext#createBiquadFilter``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createBiquadFilter)) не принимает никаких параметров. Все настройки делаются после создания элемента (например ```biquadFilterNode.type = "notch"; biquadFilterNode.frequency.value = 50;```).

*Все графики ниже отображают диапазон частот от 20 Гц до 20000 Гц. Горизонтальная ось отображает частоту, по ней применяется логарифмический масштаб, вертикальная - магнитуду (жёлтый график) от 0 до 2, или фазовый сдвиг (зелёный график) от  -Pi до Pi. Частота всех фильтров (632 Гц) отмечена красной чертой на графике.*

#### Lowpass
<img src="images/lowpass.png" width="100%" alt="Рис. 1. Фильтр lowpass." />
*Рис. 1. Фильтр lowpass.*

Пропускает только частоты ниже заданной частоты. Фильтр задаётся частотой и добротностью.

#### Highpass
<img src="images/highpass.png" width="100%" alt="Рис. 2. Фильтр highpass." />
*Рис. 2. Фильтр highpass.*

Действует аналогично lowpass, за исключением того, что он пропускает частоты выше заданной, а не ниже.

#### Bandpass
<img src="images/bandpass.png" width="100%" alt="Рис. 3. Фильтр bandpass." />
*Рис. 3. Фильтр bandpass.*

Этот фильтр более избирателен - он пропускает только определённую полосу частот.

#### Notch
<img src="images/notch.png" width="100%" alt="Рис. 4. Фильтр notch." />
*Рис. 4. Фильтр notch.*

Является противоположностью bandpass - пропускает все частоты вне заданной полосы. Стоит, однако, отметить разность в графиках затухания воздействия и в фазовых характеристиках данных фильтров.

#### Lowshelf
<img src="images/lowshelf.png" width="100%" alt="Рис. 5. Фильтр lowshelf." />
*Рис. 5. Фильтр lowshelf.*

Является более «умной» версией highpass - усиливает или ослабляет частоты ниже заданной, частоты выше пропускает без изменений. Фильтр задаётся частотой и усилением.

#### Highshelf
<img src="images/highshelf.png" width="100%" alt="Рис. 6. Фильтр highshelf." />
*Рис. 6. Фильтр highshelf.*

Более умная версия lowpass - усиливает или ослабляет частоты выше заданной, частоты ниже пропускает без изменений.

#### Peaking
<img src="images/peaking.png" width="100%" alt="Рис. 7. Фильтр peaking." />
*Рис. 7. Фильтр peaking.*

Это уже более «умная» версия notch - он усиливает или ослабляет частоты в заданном диапазоне и пропускает остальные частоты без изменений. Фильтр задаётся частотой, усилением и добротностью.

#### Фильтр allpass
<img src="images/allpass.png" width="100%" alt="Рис. 8. Фильтр allpass." />
*Рис. 8. Фильтр allpass.*

Allpass отличается ото всех остальных - он не меняет амплитудные характеристики сигнала, вместо чего делает фазовый сдвиг заданных частот. Фильтр задаётся частотой и добротностью.

### [WaveShaperNode](https://developer.mozilla.org/en-US/docs/Web/API/WaveShaperNode)

Как я уже говорил в статье про теорию звука, данный фильтр может применяться для создания таких эффектов как [«дисторшн»](https://en.wikipedia.org/wiki/Distortion_(music)), [«овердрайв»](https://ru.wikipedia.org/wiki/Овердрайв_%28звуковой_эффект%29) и [«фузз»](https://ru.wikipedia.org/wiki/Фузз_%28эффект%29). Этот фильтр применяет к входному сигналу специальную формирующую функцию. Конкретно данная реализация этого фильтра использует не функцию, а таблицу соответствия (табулированную функцию). Каждому значению входного уровня сигнала сопоставляется некое значение из таблицы (интерполированное). Засчёт нелинейного характера функции задающей таблицу можно добиться появления новых гармоник в сигнале, за счёт чего и работают перечисленные выше эффекты. При этом новые гармоники могут иметь частоты выше, чем частоты в изначальном сигнале. Это может вызвать появления алиасов. Для компенсации данного эффекта в фильтре предусмотрена возможность повышения частоты дискретизации. Перед применением фильтра частота дискретизации повышается в указанное количество раз, применяется фильтр, затем фильтруются высокие частоты (с частотой выше частоты Найквиста для исходного сигнала) и частота снижается обратно.

Фабрика ```AudioContext#createWaveShaper``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createWaveShaper)) не принимает никаких параметров. Все настройки делаются после создания элемента (например ```waveShaperNode.curve = curveData; waveShaperNode.oversample = "2x";```).

Кривая используемая для формирования сигнала является результатом линейной интерполяции значений таблицы, заданной с помощью массива значений (```Float32Array```). Размер массива может быть произвольным, при этом первое значение массива считается значением функции в точке -1, последнее - значением в точке 1, остальные значения распределены с равными интервалами. К значениям таблицы применяется ограничение от -1 до 1. Все значения меньше -1 или больше 1 приводятся к -1 или 1 соответственно.

Неплохое видео про Waveshaper, в котором можно не только посмотреть на то, как меняется форма волны в зависимости от формирующей функции, но и послушать результат:

<iframe width="560" height="315" src="https://www.youtube.com/embed/SMaJ-MHyZE0?rel=0" frameborder="0" allowfullscreen></iframe>

### [ConvolverNode](https://developer.mozilla.org/en-US/docs/Web/API/ConvolverNode)

Фильтр, производящий [линейную свёртку](https://en.wikipedia.org/wiki/Convolution) входного сигнала с аудио-буфером, задающим некую импульсную характеристику. Свёртка аудио-потока c заданной импульсной характеристикой как бы накладывает эффекты окружения, в котором была снята импульсная характеристика на входной сигнал.

Данный фильтр реализует эффект [реверберации](https://en.wikipedia.org/wiki/Reverberation). Существует множество библиотек готовых аудио-буферов для данного фильтра, которые реализуют различные эффекты ([1](https://www.freesound.org/people/jorickhoofd/packs/9893/), [2](http://www.voxengo.com/impulses/)), подобные библиотеки хорошо находятся по запросу *impulse response mp3*.

Фабрика ```AudioContext#createConvolver``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createConvolver)) не принимает никаких параметров. Все настройки делаются после создания элемента (например ```convolverNode.buffer = largeHallReverb;```)

Также возможно применить нормализацию громкости к буферу содержащему импульсную характеристику. При этом существует подводный камень - нужно сначала выставлять значение ```convolver.normalize = true;```, а лишь затем назначать буфер, т.к. эффект от изменения данного параметра проявляется только после установки нового буфера (по-умолчанию нормализация применяется).

Этот фильтр отличается от большинства других - в нём применяется БПФ. Это стоит учитывать, т.к. для БПФ требуется заполнение буфера достаточно большого размера, а это приводит к задержке воспроизведения. Например для буфера в 4096 **УТОЧНИТЬ КАКОЙ РАЗМЕР БУФЕРА НА САМОМ ДЕЛЕ ИСПОЛЬЗУЕТСЯ** отсчётов при частоте дискретизации 44100 задержка будет составлять почти 0.1 сек, а это уже ощутимо. Плюс к тому данный буфер производит большое количество расчётов, так что он существенно повышает нагрузку на CPU (по сравнению с другими фильтрами).

### [DynamicsCompressorNode](https://developer.mozilla.org/en-US/docs/Web/API/DynamicsCompressorNode)

Данный фильтр позволяет производить динамическую компрессию громкости. Фактически он динамически меняет громкость в процессе воспроизведения, снижая её для громких фрагментов. Таким образом можно избегать клиппинга в процессе сложения и/или обработки сигналов. 

Фабрика ```AudioContext#createDynamicsCompressor``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createDynamicsCompressor)) не принимает никаких параметров. Все настройки делаются после создания элемента (например ```dynamicCompressorNode.threshold = -48; dynamicCompressorNode.ratio = 18;```)

Фильтр задаётся целым рядом различных параметров:

  - ```DynamicsCompressorNode#threshold``` - пороговое значения громкости, после которой применяется фильтр (в dBFS)
  - ```DynamicsCompressorNode#ratio``` - коэффициент компрессии. Указывает соотношение громкости входного сигнала к громкости выходного (громкости измеряются в децибелах). Чем выше значение - тем сильнее будет эффект фильтра
  - ```DynamicsCompressorNode#knee``` -  указывает верхнюю границу области сглаживания. Это нужно чтобы громкость звука не менялась резкими скачками. На деле это работает как линейная **ПРОВЕРИТЬ ЧТО ЗДЕСЬ ИСПОЛЬЗУЕТСЯ ЛИНЕЙНАЯ ФУНКЦИЯ** переходная функция - если значения громкости близко к пороговому, то снижение громкости минимально, чем выше громкость и чем она ближе к верхней границе сглаживания, тем сильнее проявляется эффект фильтра. Для фрагментов с громкостью выше верхней границы сглаживания фильтр действует в полную силу
  - ```DynamicsCompressorNode#attack``` - ещё один параметр для настройки плавных переходов. В отличие от предыдущего этот параметр регулирует скорость применения эффекта непосредственно. Задаёт количество секунд за которые уровень сигнала должен быть снижен на 10 дб
  ```DynamicsCompressorNode#release``` - действует аналогично ```DynamicsCompressorNode#attack```, но указывает не скорость снижения уровня сигнала, а наоборот - восстановления
  - ```DynamicsCompressorNode#reduction``` - единственный параметр, который отвечает не за настройку, а за получение данных. Указывает текущий уровень снижения громкости (в dBFS)
  
При применении данного фильтра следует учитывать, что он значительно ухудшает звучание музыкальных композиций в большинстве случаев, особенно если выставлена высокая скорость срабатывания и низкий порог сглаживания.

### [ScriptProcessorNode](https://developer.mozilla.org/en-US/docs/Web/API/ScriptProcessorNode)

Это API является заменой устаревшей версии ```JavaScriptNode```, и само значится как устаревшее с 29 августа 2014. Вместо него должно быть вскоре (*sic!*) реализовано API Audio Worker'ов, но его по прежнему нет ни в одном браузере (по информации на 8 декабря 2015). Так что я всё-таки опишу что это такое и как оно работает, т.к. альтернативы нет и неизвестно когда она появится.
 
Этот элемент позволяет производить фильтрацию сигнала "вручную". Однако стоит учитывать, что вся обработка данных происходит в основном потоке и это блокирующая операция, так что не стоит пытаться писать сложные функции обработки - это серьёзно скажется на быстродействии интерфейса. (Собственно говоря эта причина является основной, почему этот API является устаревшим и для чего потребовалось API Audio Worker'ов)

Фабрика ```AudioContext#createScriptProcessor``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createScriptProcessor)) принимает 3 параметра: размер буферов для входных и выходных данных, количество каналов входного сигнала, количество каналов выходного сигнала.

Обработка данных происходит внутри обработчика событий ```audioprocess``` ([man](https://developer.mozilla.org/en-US/docs/Web/Events/audioprocess)). Объект события ```AudioProcessingEvent``` ([man](https://developer.mozilla.org/en-US/docs/Web/API/AudioProcessingEvent)) содержит ссылки на буферы входного и выходного сигнала, а также время воспроизведения. Для простоты назначения обработчика события ```audioprocess``` существует синтаксический сахар в виде свойства ```AudioContext#onaudioprocess```, которому можно присвоить в качестве значения обработчик этого события. Буферы входного и выходного сигнала являются обычными экземплярами ```AudioBuffer``` и содержат данные о сигнале в формате PCM.

Материалы
---------

  * [Web Audio API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)
  * [AudioContext](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext)
  * Источники сигнала
    * Медиа-элементы
      * [MediaElementAudioSourceNode](https://developer.mozilla.org/en-US/docs/Web/API/MediaElementAudioSourceNode)
      * [AudioContext#createMediaElementSource](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createMediaElementSource)
      * [CORS](https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS)
    * Устройства ввода
      * [MediaStreamAudioSourceNode](https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamAudioSourceNode)
      * [AudioContext#createMediaStreamSource](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createMediaElementSource)
      * [MediaDevices.getUserMedia](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia)
    * Аудио-буфер
      * [AudioBufferSourceNode](https://developer.mozilla.org/en-US/docs/Web/API/AudioBufferSourceNode)
      * [AudioContext#createBufferSource](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createBufferSource)
      * [AudioBuffer](https://developer.mozilla.org/en-US/docs/Web/API/AudioBuffer)
      * [AudioContext#createBuffer](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createBuffer)
      * [wavepot.com](http://wavepot.com/)
      * [AudioContext#decodeAudioData](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/decodeAudioData)
      * [OfflineAudioContext](https://developer.mozilla.org/en-US/docs/Web/API/OfflineAudioContext)
