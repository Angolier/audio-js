Web Audio API
=============

Web Audio API - это технология, позволяющая существенно расширить возможности воспроизведения звука в браузере. К сожалению эта технология на данный момент очень молодая и её поддержка есть только в свежих версиях популярных десктопных браузеров и практически отсутствует в мобильных браузерах.
  
У Web Audio API стоит выделить 3 основных аспекта, которые особо не пересекаются и их можно рассматривать отдельно:
 
  - возможности работы с различными источниками данных
  - возможности по цифровой обработке сигнала
  - возможности по анализу сигнала
  
Источники данных
----------------

В отличие от html5-элемента ```<audio>``` Web Audio API использует принципиально другой подход к указанию источника данных. Элемент ```<audio>``` использует в качестве указания источника URI-ссылку на трек, в то время как Web Audio API требует непосредственно указания объекта, который будет предоставлять доступ к данным. В качестве одно из таких объектов как раз может служить сам объект ```<audio>```. Из подобного подхода следуют 2 вещи:

  - если требуется загружать данные по сети, это требуется делать вручную (что даёт дополнительный контроль за этим процессом) или использовать для этого элемент ```<audio>```
  - возможна непосредственная генерация данных в браузере, причём даже в процессе воспроизведения

### [MediaElementAudioSourceNode](https://developer.mozilla.org/en-US/docs/Web/API/MediaElementAudioSourceNode)

Начнём с самого простого. Данный элемент предоставляет из себя источник сигнала, источником данных которого является ```<audio>``` или ```<video>``` элемент. Этот элемент создаётся с помощью метода ```AudioContext#createMediaElementSource``` ([doc](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createMediaElementSource)), который принимает в качестве единственного параметра медиа-элемент (```<audio>``` или ```<video>```). При этом создание ```MediaElementAudioSourceNode``` перенапрявляет вывод аудио-потока из медиа-элемента в данный объект. Остальное поведение медиа-элемента при этом не изменяется. Стоит отметить 2 вещи:
  
   - у медиа-элемента по прежнему работают функции изменения громкости. Для целей воспроизведения это может не иметь особого значения, но если требуется проводить анализ сигнала лучше всего выставить медиа-элементу максимальную громкость, а итоговую громкость на выходе регулировать с помощью GainNode (об этом ещё будет рассказано позднее)
   - Web Audio API требует специальных прав на получение данных из медиа-элемента. Если трек загружается с другого сервера, то для корректной работы ```MediaElementAudioSourceNode``` требуется, чтобы у медиа-элемента был выставлен параметр ```crossOrigin``` и в ответах сервера приходил корректный заголовок ```Access-Control-Allow-Access```. В противном случае этот элемент будет нельзя использовать в качестве источника данных для Web Audio API.

### [MediaStreamAudioSourceNode](https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamAudioSourceNode)

Данный элемент представляет из себя источник сигнала, источником данных которого является аудио-вход или любой другой источник настроенный в системе или браузере пользователя. Этот элемент создаётся с помощью метода ```AudioContext#createMediaStreamSource``` ([doc](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createMediaStreamSource)), который принимает в качестве единственного параметра медиа-поток, получаемый из метода ```navigator#getUserMedia```. Основное применение данного источника - использование микрофона или линейного входа в качестве источника аудио-данных.

### [AudioBufferSourceNode](https://developer.mozilla.org/en-US/docs/Web/API/AudioBufferSourceNode)

Данный элемент представляет из себя источник сигнала, источником данных которого является [AudioBuffer](https://developer.mozilla.org/en-US/docs/Web/API/AudioBuffer). Это пожалуй самый интересный тип источников сигнала, т.к. он предоставляет те возможности, которые отсутсвуют у медиа-элементов. С помощью аудио-буфера можно формировать любой сигнал непосредственно в браузере (например таким образом это делается здесь [wavepot.com](http://wavepot.com/)). Данный источник создаётся с помощью метода ```AudioContext#createBufferSource```. В отличие от предыдущих источников, в конструктор этого не передаётся элемент буфера, он устанавливается вручную после создания элемента (например ```audioBufferSource.buffer = audioBuffer```).
